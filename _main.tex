% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amscd,amsmath,amsthm,amssymb,array,bbm,hhline,mathrsfs, enumitem, comment,booktabs,fancybox,calc,textcomp,xcolor,graphicx,bm,bbm,xspace, nicefrac,stmaryrd,url,arcs,listings,nameref,natbib}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\ssubset}{\subset\joinrel\subset}
\newcommand{\E}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\edp}{e_{D,\psi}}
\newcommand{\ind}[1]{\mathds{ 1 }_{\{{#1}\}}}
\newcommand{\inda}[1]{\mathds{ 1 }_{{#1}}}
\newcommand*{\cF}{\mathcal{F}}
\newcommand{\eps}{\varepsilon}
\newcommand{\one}{\bm{1}}
\newcommand{\htheta}{\hat{\theta}_n}
\newcommand{\iid}{\overset{i.i.d}{\sim}}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Bayesian Inference and Computation},
  pdfauthor={Dr Mengchu Li and Dr Lukas Trottner},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Bayesian Inference and Computation}
\author{Dr Mengchu Li and Dr Lukas Trottner}
\date{Semester 2, 2025}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{practicalities}{%
\chapter*{Practicalities}\label{practicalities}}
\addcontentsline{toc}{chapter}{Practicalities}

\hypertarget{module-aims}{%
\section{Module Aims}\label{module-aims}}

Bayesian inference is a set of methods where the probability of an event
occurring can be updated as more information becomes available. It is
fundamentally different from frequentist methods, which are based on
long running relative frequencies. This module gives an introduction to
the Bayesian approach to statistical analysis and the theory that
underpins it.

Students will be able to explain the distinctive features of Bayesian
methodology, understand and appreciate the role of prior distributions
and compute posterior distributions. It will cover the derivation of
posterior distributions, the construction of prior distributions, and
inference for missing data. Extensions are considered to models with
more than a single parameter and how these can be used to analyse data.
Computational methods have greatly advanced the use of Bayesian methods
and this module covers, and allows students to apply, procedures for the
sampling and analysis of intractable Bayesian problems.

By the end of the course, students should be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Demonstrate a full and rigorous understanding of all definitions
  associated with Bayesian inference and understand the differences
  between the Bayesian and frequentist approaches to inference
\item
  Demonstrate a sound understanding of the fundamental concepts of
  Bayesian inference and computational sampling methods
\item
  Understand how to make inferences assuming various population
  distributions while taking into account expert opinion and the
  implications of weak prior knowledge and large samples
\item
  Demonstrate an understanding of the principles of Markov Chain Monte
  Carlo and be able to programme an MCMC algorithm
\item
  Engage in Bayesian data analysis in diverse situations drawn from
  physics, biological, engineering and other mathematical contexts.
\end{enumerate}

\hypertarget{module-structure}{%
\section{Module Structure}\label{module-structure}}

The module is split between theory and computation. Each week will have three lectures, one computer lab and one guided study. In the labs, you will need to bring your own laptop.

\hypertarget{assessment}{%
\section{Assessment}\label{assessment}}

Assessment for this module is 50\% via an exam and 50\% via coursework
assignments during the semester. The exam will last 1h 30m and take
place during the summer exam period. There will be three coursework
assignment -- assignment 1 will be worth 10\% of the final mark, with
assignments 2 and 3 counting for 20\% each. More details about the
assignments will be made available during the semester.

\hypertarget{recommended-books-and-videos}{%
\section{Recommended Books and Videos}\label{recommended-books-and-videos}}

No books are required for this course and the whole material is
contained in these notes. However, you may find it useful to use other
resources in your studies. I recommend the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{https://link.springer.com/book/10.1007/978-0-387-92407-6}{A First Course in Bayesian Statistical Methods - Peter D.
  Hoff}.
  This is a short book that covers the basics of Bayesian inference
  and computation. To the point and well written, it's a useful place
  to look topics up.
\item
  \href{http://www.stat.columbia.edu/~gelman/book/}{Bayesian Data Analysis - Andrew Gelman, John Carlin, Hal Stern,
  David Dunson, Aki Vehtari, and Donald
  Rubin}. This is a
  thorough book explaining everything you'd need to know to carry out
  Bayesian data analysis. It's a fairly long and in-depth book, but
  the authors are authoritative and give good advice throughout.
  Example code on the website is in R, Python and Stan.
\item
  \href{https://xcelab.net/rm/statistical-rethinking/}{Statistical Rethinking - Richard
  McElrath}. This book
  provides a friendly intuitive understanding of Bayesian inference
  and computation. Aimed at social and natural scientists, it has less
  theory that the other two books but is perhaps more approachable. A
  set of video lectures for this book can be found on
  \href{https://www.youtube.com/playlist?list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN}{YouTube}.
\end{enumerate}

\hypertarget{common-distributions}{%
\section{Common Distributions}\label{common-distributions}}

For many Bayesian inference problems, it is useful to be able to
identify probability density functions (for continuous random variables)
and probability mass functions (for discrete random variables) up to
proportionality. Some common density/mass functions are given below.

\textbf{Normal distribution} \(N(\mu,\sigma^2)\)
\[
\pi(x \mid \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left\{-\frac{1}{2\sigma^2}(x-\mu)^2\right\} \qquad x \in\mathbb{R},
\] where \(\mu \in \mathbb{R}\) and \(\sigma > 0\).

\textbf{Beta distribution} \(\text{Beta}(\alpha,\beta)\)
\[
\pi(x\mid \alpha, \beta) = \frac{1}{B(\alpha, \beta)}x^{\alpha-1}(1-x)^{\beta - 1} \qquad  x \in [0, 1],
\] where \(\alpha, \beta > 0\) and \(B(\alpha, \beta)\) is the \href{https://en.wikipedia.org/wiki/Beta_function}{Beta
function}.

\textbf{Gamma distribution} \(\text{Gamma}(\alpha,\beta)\)
\[
\pi(x\mid \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha - 1}e^{-\beta x} \qquad  x > 0,
\] where \(\alpha, \beta > 0\) and \(\Gamma(\alpha)\) is the \href{https://en.wikipedia.org/wiki/Gamma_function}{Gamma
function}.

\textbf{Exponential distribution} \(\text{Exp}(\lambda)\)
\[
f(x \mid \lambda) = \lambda e^{-\lambda x} \qquad x > 0,
\] where \(\lambda > 0\).

\textbf{Poisson distribution} \(\text{Poi}(\lambda)\)
\[
\pi(x = k \mid \lambda) = \frac{\lambda^k e^{-\lambda}}{k!} \qquad k \in \{1, 2, \ldots\},
\] where \(\lambda > 0\).

\textbf{Binomial distribution} \(\text{Bin}(N,p)\)
\[
\pi(x = k \mid N, p) = \begin{pmatrix} N \\ k\end{pmatrix} p^k (1-p)^{N-k} \qquad k \in \{1, \ldots, N\}
\]
where \(p \in [0, 1]\).

\hypertarget{fundamentals}{%
\chapter{Fundamentals of Bayesian Inference}\label{fundamentals}}

Placeholder

\hypertarget{statistical-inference}{%
\section{Statistical Inference}\label{statistical-inference}}

\hypertarget{frequentist-theory}{%
\section{Frequentist Theory}\label{frequentist-theory}}

\hypertarget{bayesian-paradigm}{%
\section{Bayesian Paradigm}\label{bayesian-paradigm}}

\hypertarget{probability-basics-and-exchangability}{%
\section{Probability Basics and Exchangability}\label{probability-basics-and-exchangability}}

\hypertarget{bayes-theorem}{%
\section{Bayes' Theorem}\label{bayes-theorem}}

\hypertarget{programming-in-r}{%
\chapter{Programming in R}\label{programming-in-r}}

Placeholder

\hypertarget{random-numbers-for-loops-and-r}{%
\section{Random Numbers, For Loops and R}\label{random-numbers-for-loops-and-r}}

\hypertarget{functions-in-r}{%
\section{Functions in R}\label{functions-in-r}}

\hypertarget{built-in-commands}{%
\subsection{Built in commands}\label{built-in-commands}}

\hypertarget{user-defined-functions}{%
\subsection{User defined functions}\label{user-defined-functions}}

\hypertarget{good-coding-practices}{%
\section{Good Coding Practices}\label{good-coding-practices}}

\hypertarget{code-style}{%
\subsection{Code Style}\label{code-style}}

\hypertarget{bayesian-inference}{%
\chapter{Bayesian Inference}\label{bayesian-inference}}

Placeholder

\hypertarget{the-binomial-distribution}{%
\section{The Binomial Distribution}\label{the-binomial-distribution}}

\hypertarget{reporting-conclusions-from-bayesian-inference}{%
\section{Reporting Conclusions from Bayesian Inference}\label{reporting-conclusions-from-bayesian-inference}}

\hypertarget{the-exponential-distribution}{%
\section{The Exponential Distribution}\label{the-exponential-distribution}}

\hypertarget{the-normal-distribtuion}{%
\section{The Normal Distribtuion}\label{the-normal-distribtuion}}

\hypertarget{hierarchical-models}{%
\section{Hierarchical Models}\label{hierarchical-models}}

\hypertarget{prediction}{%
\section{Prediction}\label{prediction}}

\hypertarget{non-informative-prior-distibrutions}{%
\section{Non-informative Prior Distibrutions}\label{non-informative-prior-distibrutions}}

\hypertarget{bernstein-von-mises-theorem}{%
\section{Bernstein-von-Mises Theorem}\label{bernstein-von-mises-theorem}}

\hypertarget{lab}{%
\section{Lab}\label{lab}}

\hypertarget{sampling}{%
\chapter{Sampling}\label{sampling}}

Placeholder

\hypertarget{uniform-random-numbers}{%
\section{Uniform Random Numbers}\label{uniform-random-numbers}}

\hypertarget{inverse-transform-sampling}{%
\section{Inverse Transform Sampling}\label{inverse-transform-sampling}}

\hypertarget{rejection-sampling}{%
\section{Rejection Sampling}\label{rejection-sampling}}

\hypertarget{rejection-sampling-efficiency}{%
\subsection{Rejection Sampling Efficiency}\label{rejection-sampling-efficiency}}

\hypertarget{ziggurat-sampling}{%
\section{Ziggurat Sampling}\label{ziggurat-sampling}}

\hypertarget{approximate-bayesian-computation}{%
\section{Approximate Bayesian Computation}\label{approximate-bayesian-computation}}

\hypertarget{abc-with-rejection}{%
\subsection{ABC with Rejection}\label{abc-with-rejection}}

\hypertarget{summary-abc-with-rejection}{%
\subsection{Summary ABC with Rejection}\label{summary-abc-with-rejection}}

\hypertarget{lab-1}{%
\section{Lab}\label{lab-1}}

\hypertarget{markov-chain-monte-carlo}{%
\chapter{Markov Chain Monte Carlo}\label{markov-chain-monte-carlo}}

Placeholder

\hypertarget{properties-of-markov-chains}{%
\section{Properties of Markov Chains}\label{properties-of-markov-chains}}

\hypertarget{metropolishastings}{%
\section{Metropolis--Hastings}\label{metropolishastings}}

\hypertarget{gibbs-sampler}{%
\section{Gibbs Sampler}\label{gibbs-sampler}}

\hypertarget{metropolis-within-gibbs}{%
\section{Metropolis-within-Gibbs}\label{metropolis-within-gibbs}}

\hypertarget{mcmc-diagnostics}{%
\section{MCMC Diagnostics}\label{mcmc-diagnostics}}

\hypertarget{beyond-mcmc}{%
\section{Beyond MCMC}\label{beyond-mcmc}}

\hypertarget{lab-2}{%
\section{Lab}\label{lab-2}}

\hypertarget{markov-chain-monte-carlo-1}{%
\chapter{Markov Chain Monte Carlo}\label{markov-chain-monte-carlo-1}}

Placeholder

\hypertarget{properties-of-markov-chains-1}{%
\section{Properties of Markov Chains}\label{properties-of-markov-chains-1}}

\hypertarget{metropolishastings-1}{%
\section{Metropolis--Hastings}\label{metropolishastings-1}}

\hypertarget{gibbs-sampler-1}{%
\section{Gibbs Sampler}\label{gibbs-sampler-1}}

\hypertarget{metropolis-within-gibbs-1}{%
\section{Metropolis-within-Gibbs}\label{metropolis-within-gibbs-1}}

\hypertarget{mcmc-diagnostics-1}{%
\section{MCMC Diagnostics}\label{mcmc-diagnostics-1}}

\hypertarget{beyond-mcmc-1}{%
\section{Beyond MCMC}\label{beyond-mcmc-1}}

\hypertarget{lab-3}{%
\section{Lab}\label{lab-3}}

\hypertarget{advanced-computation}{%
\chapter{Advanced Computation}\label{advanced-computation}}

Placeholder

\hypertarget{gaussian-processes}{%
\section{Gaussian Processes}\label{gaussian-processes}}

\hypertarget{covariance-functions}{%
\subsection{Covariance Functions}\label{covariance-functions}}

\hypertarget{gaussian-process-regression}{%
\subsection{Gaussian Process Regression}\label{gaussian-process-regression}}

\hypertarget{data-augmentation}{%
\section{Data Augmentation}\label{data-augmentation}}

\hypertarget{imputing-censored-observations}{%
\subsection{Imputing censored observations}\label{imputing-censored-observations}}

\hypertarget{imputing-latent-variables}{%
\subsection{Imputing Latent Variables}\label{imputing-latent-variables}}

\hypertarget{grouped-data}{%
\subsection{Grouped Data}\label{grouped-data}}

\hypertarget{prior-ellicitation}{%
\section{Prior Ellicitation}\label{prior-ellicitation}}

\hypertarget{prior-summaries}{%
\subsection{Prior Summaries}\label{prior-summaries}}

\hypertarget{betting-with-histograms}{%
\subsection{Betting with Histograms}\label{betting-with-histograms}}

\hypertarget{prior-intervals}{%
\subsection{Prior Intervals}\label{prior-intervals}}

\hypertarget{lab-4}{%
\section{Lab}\label{lab-4}}

\hypertarget{gaussian-processes-1}{%
\subsection{Gaussian Processes}\label{gaussian-processes-1}}

\hypertarget{missing-data}{%
\subsection{Missing Data}\label{missing-data}}

  \bibliography{book.bib,packages.bib}

\end{document}
